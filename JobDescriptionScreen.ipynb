{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JobDescriptionScreen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S70-Gw3GnwYz",
        "colab_type": "text"
      },
      "source": [
        "### Job description screening by NLP\n",
        "Chiyuan Cheng\n",
        "- load job description in google sheet and find the matching keywords by NLP\n",
        "- A small project for information extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVGkWqYpl4zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing all required libraries\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQfdNyFJmqvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import PyPDF2\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from io import StringIO\n",
        "\n",
        "import spacy #use NLP functions\n",
        "from spacy import displacy\n",
        "import en_core_web_sm # pre-train model\n",
        "nlp = en_core_web_sm.load()\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import nltk #NLP data processing library (IMDB)\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.phrases import Phraser, Phrases # phraser optimizes phrases\n",
        "\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import string\n",
        "from gensim.models.phrases import Phraser, Phrases # phraser optimizes phrases\n",
        "from keras.preprocessing.text import one_hot # relation\n",
        "from textblob import TextBlob\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from bokeh.io import output_notebook, output_file\n",
        "from bokeh.plotting import show, figure\n",
        "\n",
        "from keras.preprocessing.text import one_hot # relation\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ZKeSh1P4Dw",
        "colab_type": "text"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_QZKnVgm_wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data from google sheet\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1_7xr5Wfe1Zxz31fRAg4HxM7579p7pLyv2DQeynqAeNQ/edit?folder=1Zdk9qp8mD6x93sdLr14SMf-iczSrlrsP#gid=0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1q7etvanhNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_googlesheet(sheetname):\n",
        "  '''\n",
        "  input sheetname\n",
        "  output pd.dataframe\n",
        "  '''\n",
        "  sheet = wb.worksheet(sheetname) # sheet name\n",
        "  data = sheet.get_all_values() # load sheet\n",
        "  df = pd.DataFrame(data)\n",
        "  df.columns = df.iloc[0]\n",
        "  df = df.iloc[1:]\n",
        "  df=df.reset_index(drop=True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ooYXR_TPVvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data for job discription\n",
        "df_jd = load_googlesheet('Sheet1')\n",
        "# data for keywords\n",
        "df_kw = load_googlesheet('keywords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9ySbvi8Mbvp",
        "colab_type": "code",
        "outputId": "9a72ae7b-3382-4dd4-899f-fbdf49394e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "display(df_jd.head(3))\n",
        "display(df_kw.head(3))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Financial</th>\n",
              "      <th>Healthcare</th>\n",
              "      <th>e-com</th>\n",
              "      <th>social media</th>\n",
              "      <th>consumer</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two Sigma, The Alpha Insights team at Two Sigm...</td>\n",
              "      <td>Novo Nordisk, The Clinical, Medical and Regula...</td>\n",
              "      <td>Walmart Position Description\\n\\nA Staff Data S...</td>\n",
              "      <td>Facebook, We’re looking for Data Scientists to...</td>\n",
              "      <td>Uniliever, Background &amp; Purpose of the Job\\n\\n...</td>\n",
              "      <td>Google, Note: By applying to this position you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prudential Financial,\\n\\nAs we create a divers...</td>\n",
              "      <td>Aetna, Description:\\r\\nIt’s a new day in healt...</td>\n",
              "      <td>Walmart, As a part of Walmart’s Customer Data ...</td>\n",
              "      <td>Facebook, With over 2.1 billion people, our co...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Machine Learning Research Scientist - Pattern ...</td>\n",
              "      <td>Blink Health, Blink Health ( https://www.blink...</td>\n",
              "      <td>Amazon, Description\\r\\n\\r\\nAre you seeking an ...</td>\n",
              "      <td>New York Times, The New York Times is a techno...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                          Financial  ...                                        Information\n",
              "0  Two Sigma, The Alpha Insights team at Two Sigm...  ...  Google, Note: By applying to this position you...\n",
              "1  Prudential Financial,\\n\\nAs we create a divers...  ...                                                   \n",
              "2  Machine Learning Research Scientist - Pattern ...  ...                                                   \n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statistics</th>\n",
              "      <th>machine learning</th>\n",
              "      <th>deep learning</th>\n",
              "      <th>python langugage</th>\n",
              "      <th>R language</th>\n",
              "      <th>nlp</th>\n",
              "      <th>data engineering</th>\n",
              "      <th>visualization</th>\n",
              "      <th>soft skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>statistical models</td>\n",
              "      <td>linear regression</td>\n",
              "      <td>neural network</td>\n",
              "      <td>flask</td>\n",
              "      <td>R</td>\n",
              "      <td>natural language processing</td>\n",
              "      <td>aws</td>\n",
              "      <td>matplotlib</td>\n",
              "      <td>Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>statistical modeling</td>\n",
              "      <td>logestic regression</td>\n",
              "      <td>keras</td>\n",
              "      <td>pandas</td>\n",
              "      <td>ggplot</td>\n",
              "      <td>topic modeling</td>\n",
              "      <td>ecs</td>\n",
              "      <td>seaborn</td>\n",
              "      <td>experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>probability</td>\n",
              "      <td>k means</td>\n",
              "      <td>theano</td>\n",
              "      <td>numpy</td>\n",
              "      <td>shiny</td>\n",
              "      <td>lda</td>\n",
              "      <td>amazon redshift</td>\n",
              "      <td>visualization</td>\n",
              "      <td>outside the box</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0            statistics     machine learning  ...  visualization      soft skills\n",
              "0    statistical models    linear regression  ...     matplotlib    Communication\n",
              "1  statistical modeling  logestic regression  ...        seaborn       experience\n",
              "2           probability              k means  ...  visualization  outside the box\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFELn4z9P6iI",
        "colab_type": "text"
      },
      "source": [
        "#### Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ur66_Ux2lpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean = df_jd.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DAb3JwQn8YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove punctuations and lowercase\n",
        "result_punctuation = string.punctuation + str('\\n') + str('\\r')\n",
        "for names in df_clean.columns:\n",
        "  for i in range(df_clean[names].shape[0]):\n",
        "    for char in df_clean[names][i]:\n",
        "      if char in result_punctuation:\n",
        "        df_clean[names][i] = df_clean[names][i].replace(char, \" \").lower()#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6ugCIKBmoO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d32eeb26-d907-4376-fee7-3ce7fa8383a2"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Financial</th>\n",
              "      <th>Healthcare</th>\n",
              "      <th>e-com</th>\n",
              "      <th>social media</th>\n",
              "      <th>consumer</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>two sigma  the alpha insights team at two sigm...</td>\n",
              "      <td>novo nordisk  the clinical  medical and regula...</td>\n",
              "      <td>walmart position description  a staff data sci...</td>\n",
              "      <td>facebook  we’re looking for data scientists to...</td>\n",
              "      <td>uniliever  background   purpose of the job  as...</td>\n",
              "      <td>google  note  by applying to this position you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prudential financial   as we create a diverse ...</td>\n",
              "      <td>aetna  description   it’s a new day in health ...</td>\n",
              "      <td>walmart  as a part of walmart’s customer data ...</td>\n",
              "      <td>facebook  with over 2 1 billion people  our co...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine learning research scientist   pattern ...</td>\n",
              "      <td>blink health  blink health   https   www blink...</td>\n",
              "      <td>amazon  description    are you seeking an envi...</td>\n",
              "      <td>new york times  the new york times is a techno...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>venmo  about us  venmo was founded on the prin...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  description    amazon is looking for a...</td>\n",
              "      <td>wolters kluwer  data scientist – r0006015  wol...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sofi  who we are  sofi is a digital personal f...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  where will amazon s growth come from i...</td>\n",
              "      <td>bloomberg  news and social media move financia...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                          Financial  ...                                        Information\n",
              "0  two sigma  the alpha insights team at two sigm...  ...  google  note  by applying to this position you...\n",
              "1  prudential financial   as we create a diverse ...  ...                                                   \n",
              "2  machine learning research scientist   pattern ...  ...                                                   \n",
              "3  venmo  about us  venmo was founded on the prin...  ...                                                   \n",
              "4  sofi  who we are  sofi is a digital personal f...  ...                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KZ7qwvKWnYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4a68c871-c755-4e91-cbaa-084b30f56136"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Financial</th>\n",
              "      <th>Healthcare</th>\n",
              "      <th>e-com</th>\n",
              "      <th>social media</th>\n",
              "      <th>consumer</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>two sigma  the alpha insights team at two sigm...</td>\n",
              "      <td>novo nordisk  the clinical  medical and regula...</td>\n",
              "      <td>walmart position description  a staff data sci...</td>\n",
              "      <td>facebook  we’re looking for data scientists to...</td>\n",
              "      <td>uniliever  background   purpose of the job  as...</td>\n",
              "      <td>google  note  by applying to this position you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prudential financial   as we create a diverse ...</td>\n",
              "      <td>aetna  description   it’s a new day in health ...</td>\n",
              "      <td>walmart  as a part of walmart’s customer data ...</td>\n",
              "      <td>facebook  with over 2 1 billion people  our co...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine learning research scientist   pattern ...</td>\n",
              "      <td>blink health  blink health   https   www blink...</td>\n",
              "      <td>amazon  description    are you seeking an envi...</td>\n",
              "      <td>new york times  the new york times is a techno...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>venmo  about us  venmo was founded on the prin...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  description    amazon is looking for a...</td>\n",
              "      <td>wolters kluwer  data scientist – r0006015  wol...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sofi  who we are  sofi is a digital personal f...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  where will amazon s growth come from i...</td>\n",
              "      <td>bloomberg  news and social media move financia...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                          Financial  ...                                        Information\n",
              "0  two sigma  the alpha insights team at two sigm...  ...  google  note  by applying to this position you...\n",
              "1  prudential financial   as we create a diverse ...  ...                                                   \n",
              "2  machine learning research scientist   pattern ...  ...                                                   \n",
              "3  venmo  about us  venmo was founded on the prin...  ...                                                   \n",
              "4  sofi  who we are  sofi is a digital personal f...  ...                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBb8ZkCOokZ1",
        "colab_type": "text"
      },
      "source": [
        "stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyLdU2garrC3",
        "colab_type": "code",
        "outputId": "e842ac74-7589-45df-be6d-b6357ae447ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# print stop words from spacy\n",
        "nlp = en_core_web_sm.load()  # spacy language model\n",
        "stop_words = list(spacy.lang.en.stop_words.STOP_WORDS) + list(string.punctuation) \n",
        "stop_words.append('two')\n",
        "print(stop_words)\n",
        "print('numbers of stopwords =',len(stop_words))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['’ll', 'ca', 'out', 'into', 'seems', 'doing', 'it', 'beforehand', 'down', 'from', 'three', 'neither', \"'m\", 'made', 'former', 'elsewhere', 'if', 'take', '’ve', 'put', 'seemed', 'forty', 'eight', 'whereafter', 'perhaps', 'at', '‘s', 'say', 'each', 'always', 'as', 'was', '’re', 'about', 'him', 'back', 'just', 'really', 'myself', 'sometime', 'twelve', 'wherein', 'well', 'with', 'once', 'there', 'seeming', '‘re', 'hereafter', 'bottom', 'third', 'nor', 'might', 'why', 'five', \"'ll\", 'call', 'give', 'in', 'have', 'do', 'where', \"n't\", 'please', 'their', 'among', 'some', 'yourself', 'should', 'almost', 'below', 'over', 'whereupon', 'therefore', 'were', 'would', 'you', 'else', 'every', 'become', 'serious', 'alone', 'twenty', 'them', 'thereafter', 'often', 'whither', \"'s\", 'but', 'hundred', 'an', \"'d\", 'one', 'side', 'herself', 'being', 'on', 'when', 'she', 'around', '‘ve', 'much', 'whatever', 'since', 'whenever', 'because', 'although', 'same', 'thereby', 'nobody', 'done', 'mine', 'so', 'those', 'anywhere', 'next', 'everything', 'seem', 'and', 'cannot', 'still', 'enough', 'meanwhile', 'they', 'which', 'after', 'few', 'my', 'somewhere', 'though', 'your', 'nothing', 'six', 'whereby', 'most', 'go', '’s', 'see', 'anyway', 'no', 'otherwise', 'moreover', 'becoming', 'amongst', 'something', 'thence', 'therein', '‘d', 'last', 'herein', 'i', 'more', 'of', 'very', 'until', 'whether', 'all', 'thru', 'by', 'noone', 'amount', 'the', 'not', 'unless', 'make', 'beside', 'did', 'ten', 'up', 'are', 'fifty', 'her', 'however', 'within', 'how', 'another', 'several', 'someone', 'many', 'name', 'also', 'get', 'hereby', 'or', 'ourselves', 'everywhere', 'any', 'both', 'latter', 'becomes', 'may', 'now', 'other', 'wherever', 'who', \"'ve\", 'is', 'such', 'then', 'together', 'whence', 'own', 'front', '’m', 'along', '’d', 'except', 'for', 'four', 're', 'somehow', 'behind', 'namely', 'hereupon', 'these', 'various', 'yours', 'must', 'already', 'none', 'whose', 'will', 'per', 'again', 'toward', 'ever', 'am', 'n’t', 'empty', 'here', 'rather', 'be', 'top', 'thus', 'without', 'during', 'nine', 'less', 'further', 'a', 'through', 'too', 'two', 'themselves', 'us', 'sometimes', 'we', 'whole', 'besides', 'thereupon', 'using', 'upon', 'formerly', 'itself', 'either', 'others', 'nowhere', 'can', 'due', 'quite', 'to', 'onto', 'part', 'this', 'towards', 'has', 'beyond', 'latterly', 'had', 'between', 'afterwards', 'than', 'his', 'our', 'while', 'sixty', 'that', 'before', 'does', '‘m', 'me', 'used', 'regarding', 'via', 'n‘t', 'never', 'anyhow', 'hers', 'could', 'himself', 'keep', 'eleven', 'first', 'been', 'became', 'he', 'anyone', 'hence', '‘ll', 'nevertheless', 'under', 'whoever', 'ours', 'least', \"'re\", 'only', 'anything', 'its', 'mostly', 'indeed', 'whom', 'what', 'full', 'against', 'yourselves', 'show', 'off', 'whereas', 'throughout', 'fifteen', 'across', 'even', 'everyone', 'move', 'above', 'yet', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'two']\n",
            "numbers of stopwords = 359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNw7gdwGoqX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to remove the stopwords\n",
        "def stwds(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "# Applying the stopwords to 'text_punct' and store into 'text_stop'\n",
        "#df_clean[\"Financial_stop\"] = \n",
        "#df_clean[\"Financial\"].apply(stwds)\n",
        "#df_clean[\"Financial_stop\"].head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNOP3WxpceS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "7386424c-12ab-4eab-fd12-b56756601353"
      },
      "source": [
        "#[w for w in df_clean.iloc[:,0] if w =='two']\n",
        "#df_clean.iloc[:,5].apply(stwds)\n",
        "for w in df_clean.iloc[:,0].str.split():\n",
        "  #if w in stop_words:\n",
        "    print('---')\n",
        "    print(w)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "['two', 'sigma', 'the', 'alpha', 'insights', 'team', 'at', 'two', 'sigma', 'is', 'looking', 'for', 'an', 'entrepreneurial', 'data', 'scientist', 'to', 'contribute', 'to', 'its', 'data', 'driven', 'investment', 'initiatives', 'alpha', 'insights', 'crowdsources', 'the', 'world’s', 'investment', 'insights', 'and', 'through', 'such', 'data', 'creation', 'we', 'are', 'an', 'integral', 'part', 'of', 'two', 'sigma', 'investment', 'management', 'process', 'we', 'interact', 'with', 'people', 'external', 'to', 'the', 'firm', 'to', 'collect', 'and', 'analyze', 'their', 'investment', 'insights', 'through', 'our', 'web', 'and', 'mobile', 'products', 'data', 'science', 'in', 'alpha', 'insights', 'has', '3', 'missions', '1', 'make', 'relevant', 'data', 'and', 'metrics', 'accessible', 'to', 'the', 'team', '2', 'perform', 'analyses', 'to', 'guide', 'business', 'and', 'product', 'decisions', 'and', '3', 'build', 'data', 'driven', 'features', 'that', 'power', 'our', 'products', 'you', 'will', 'take', 'on', 'the', 'following', 'responsibilities', 'deliver', 'metrics', 'and', 'analyses', 'to', 'all', 'functions', 'within', 'alpha', 'insights', 'including', 'product', 'design', 'and', 'business', 'units', 'write', 'etls', 'to', 'convert', 'structure', 'unstructured', 'data', 'into', 'stable', 'data', 'assets', 'build', 'visualizations', 'to', 'enable', 'team', 'members', 'to', 'extract', 'relevant', 'insights', 'apply', 'statistical', 'analysis', 'and', 'exploratory', 'techniques', 'to', 'enable', 'data', 'driven', 'decision', 'making', 'own', 'data', 'driven', 'product', 'components', 'e', 'g', 'ranking', 'and', 'recommendation', 'algorithms', 'you', 'should', 'possess', 'the', 'following', 'qualifications', '3', '5', 'years', 'of', 'experience', 'in', 'data', 'analysis', 'or', 'similar', 'role', 'ms', 'or', 'phd', 'in', 'computer', 'science', 'statistics', 'economics', 'or', 'related', 'quantitative', 'field', 'experience', 'applying', 'statistical', 'methods', 'distribution', 'analysis', 'classification', 'regression', 'clustering', 'etc', 'application', 'of', 'these', 'methods', 'to', 'user', 'behavior', 'a', 'plus', 'demonstrated', 'experience', 'highlighting', 'innovation', 'creativity', 'and', 'intuition', 'e', 'g', 'the', 'ability', 'to', 'laterally', 'identify', 'other', 'sources', 'of', 'useful', 'information', 'and', 'think', 'outside', 'the', 'box', 'strong', 'data', 'transformation', 'skills', 'e', 'g', 'using', 'pandas', 'r', 'software', 'engineering', 'skills', 'in', 'at', 'least', 'one', 'imperative', 'programming', 'language', 'communication', 'skills', 'to', 'explain', 'metrics', 'analyses', 'to', 'members', 'of', 'management', 'engineering', 'product', 'and', 'business', 'teams', 'prior', 'experience', 'in', 'finance', 'is', 'not', 'required']\n",
            "---\n",
            "['prudential', 'financial', 'as', 'we', 'create', 'a', 'diverse', 'growing', 'and', 'dynamic', 'workforce', 'within', 'a', 'technology', 'community', 'that', 's', 'respected', 'for', 'delivering', 'high', 'tech', 'solutions', 'data', 'driven', 'solutions', 'are', 'at', 'the', 'core', 'of', 'it', 'all', 'to', 'this', 'end', 'isg', 'technology', 'is', 'seeking', 'a', 'qualified', 'senior', 'data', 'scientist', 'with', 'experience', 'in', 'designing', 'solutions', 'to', 'business', 'problems', 'using', 'machine', 'learning', 'big', 'data', 'techniques', 'and', 'technologies', 'the', 'ideal', 'candidate', 'is', 'a', 'data', 'driven', 'problem', 'solver', 'with', 'an', 'ability', 'to', 'translate', 'business', 'requirements', 'into', 'mathematical', 'models', 'the', 'candidate', 'will', 'also', 'have', 'an', 'ability', 'to', 'develop', 'solutions', 'to', 'complex', 'mathematical', 'and', 'data', 'problems', 'discover', 'insights', 'and', 'identify', 'opportunities', 'through', 'the', 'use', 'of', 'statistical', 'algorithmic', 'data', 'mining', 'and', 'visualization', 'techniques', 'partnering', 'with', 'a', 'team', 'of', 'technology', 'and', 'business', 'data', 'specialists', 'the', 'candidate', 'will', 'use', 'their', 'analytic', 'and', 'engineering', 'skills', 'to', 'integrate', 'and', 'prepare', 'large', 'varied', 'datasets', 'and', 'architecting', 'specialized', 'solutions', 'in', 'cloud', 'environments', 'employing', 'a', 'range', 'of', 'machine', 'learning', 'and', 'data', 'science', 'techniques', 'while', 'effectively', 'communicating', 'results', 'to', 'various', 'interested', 'parties', 'this', 'is', 'a', 'dynamic', 'environment', 'where', 'the', 'right', 'candidate', 'will', 'be', 'comfortable', 'and', 'capable', 'of', 'operating', 'in', '“test', 'and', 'learn”', 'mode', 'and', 'work', 'independently', 'key', 'responsibilities', 'utilize', 'emerging', 'data', 'technologies', 'and', 'techniques', 'to', 'solve', 'data', 'driven', 'problems', 'lead', 'influence', 'and', 'participate', 'in', 'the', 'end', 'to', 'end', 'data', 'lifecycle', 'activities', 'identify', 'business', 'problems', 'engage', 'with', 'business', 'teams', 'build', 'hypotheses', 'define', 'and', 'build', 'compute', 'environments', 'and', 'automated', 'data', 'pipelines', 'drive', 'data', 'engineering', 'activities', 'discovery', 'sourcing', 'wrangling', 'cleansing', 'and', 'modeling', 'apply', 'machine', 'learning', 'techniques', 'and', 'various', 'algorithms', 'to', 'provide', 'problem', 'solving', 'insights', 'create', 'meaningful', 'insights', 'through', 'data', 'visualization', 'simple', 'effective', 'results', 'communication', 'work', 'as', 'a', 'liaison', 'between', 'business', 'partners', 'and', 'junior', 'data', 'scientists', 'to', 'refine', 'data', 'science', 'activity', 'participate', 'in', 'management', 'meetings', 'to', 'help', 'establish', 'data', 'roadmap', 'and', 'strategies', 'experience', 'with', 'algorithms', 'and', 'programming', 'to', 'efficiently', 'process', 'large', 'datasets', 'and', 'apply', 'treatments', 'filters', 'and', 'conditions', 'to', 'your', 'data', 'experience', 'with', 'big', 'data', 'technologies', 'such', 'as', 'hadoop', '2', '0', 'hbase', 'mongo', 'informatica', 'cloudera', 'vertica', 'green', 'plum', 'netezza', 'proficient', 'with', 'practical', 'experience', 'with', 'data', 'engineering', 'data', 'discovery', 'cleansing', 'wrangling', 'and', 'modeling', 'the', 'ability', 'to', 'organize', 'and', '“wrangle”', 'large', 'datasets', 'so', 'that', 'you', 'can', 'get', 'actionable', 'insights', 'from', 'them', 'this', 'may', 'include', 'finding', 'innovative', 'ways', 'to', 'combine', 'fields', 'of', 'data', 'that', 'don’t', 'naturally', 'mesh', 'together', 'experience', 'defining', 'and', 'creating', 'automated', 'data', 'pipelines', 'and', 'performing', 'advanced', 'data', 'manipulation', 'interest', 'in', 'understanding', 'the', 'business', 'problems', 'and', 'how', 'the', 'work', 'impacts', 'the', 'business', 'enthusiastic', 'yet', 'humble', '–', 'you', 'are', 'excited', 'about', 'the', 'work', 'you', 'do', 'but', 'you', 'are', 'also', 'humble', 'enough', 'to', 'embrace', 'feedback', '–', 'you', 'don’t', 'need', 'to', 'be', 'the', 'smartest', 'person', 'in', 'the', 'room', 'experience', 'with', 'machine', 'learning', 'methods', 'techniques', 'and', 'algorithms', 'classification', 'and', 'regression', 'clustering', 'decision', 'trees', 'neural', 'networks', 'time', 'series', 'analysis', 'etc', 'firm', 'understanding', 'of', 'statistics', 'statistical', 'tests', 'distributions', 'maximum', 'likelihood', 'estimators', 'etc', 'experience', 'with', 'visualization', 'and', 'reporting', 'technologies', 'such', 'as', 'tableau', 'power', 'bi', 'and', 'or', 'programmatic', 'visualizations', 'in', 'plotly', 'sas', 'python', 'etc', 'the', 'ability', 'to', 'create', 'meaningful', 'data', 'visualizations', 'that', 'communicate', 'your', 'findings', 'and', 'demonstrate', 'how', 'your', 'insights', 'create', 'business', 'impact', 'excellent', 'written', 'and', 'verbal', 'communication', 'skills', 'an', 'entrepreneurial', 'mindset', 'with', 'the', 'ability', 'to', 'adopt', 'novel', 'solutions', 'in', 'a', 'fast', 'paced', 'environment', 'to', 'deliver', 'results', 'quickly', 'help', 'junior', 'team', 'members', 'along', 'the', 'way', 'able', 'to', 'work', 'collaboratively', 'as', 'a', 'senior', 'member', 'of', 'the', 'team', 'but', 'with', 'creative', 'and', 'individual', 'thinking', 'previous', 'experience', 'in', 'working', 'in', 'high', 'growth', 'data', 'driven', 'and', 'or', 'innovative', 'businesses', 'experience', 'with', 'lean', 'and', 'or', 'scrum', 'development', 'methodologies', 'a', 'plus', 'ms', 'or', 'phd', 'in', 'computer', 'science', 'math', 'or', 'engineering', 'or', 'other', 'quantitative', 'field', 'work', 'experience', 'can', 'substitute', 'for', 'experience', 'experience', 'with', 'time', 'series', 'analysis', 'is', 'a', 'plus', 'experience', 'with', 'aws', 'machine', 'learning', 'suite', 'of', 'tools', 'is', 'a', 'plus', 'experience', 'with', 'applying', 'data', 'science', 'to', 'problems', 'in', 'insurance', 'and', 'or', 'other', 'financial', 'industries', 'is', 'a', 'plus', 'experience', 'with', 'analyzing', 'data', 'from', 'social', 'media', 'platforms', 'a', 'plus', 'knowledge', 'of', 'image', 'data', 'analysis', 'and', 'computer', 'vision', 'a', 'plus', 'knowledge', 'of', 'natural', 'language', 'processing', 'a', 'plus']\n",
            "---\n",
            "['machine', 'learning', 'research', 'scientist', 'pattern', 'recognition', 'we', 'ingests', 'more', 'than', '1', '5', 'million', 'news', 'stories', 'per', 'day', 'from', 'more', 'than', '120', '000', 'different', 'sources', 'to', 'help', 'our', 'clients', 'stay', 'in', 'the', 'know', 'this', 'data', 'would', 'be', 'unmanageable', 'without', 'our', 'help', 'news', 'stories', 'move', 'markets', 'we', 'build', 'machines', 'that', 'understand', 'them', 'with', 'the', 'ever', 'increasing', 'amount', 'of', 'data', 'being', 'generated', 'our', 'clients', 'need', 'ever', 'more', 'sophisticated', 'ways', 'of', 'extracting', 'signal', 'from', 'noise', 'the', 'pattern', 'recognition', 'team', 'in', 'the', 'machine', 'learning', 'group', 'is', 'responsible', 'for', 'building', 'a', 'wide', 'variety', 'of', 'analytics', 'and', 'recommendation', 'systems', 'to', 'surface', 'insights', 'e', 'g', 'identify', 'market', 'moving', 'news', 'stories', 'create', 'new', 'events', 'that', 'are', 'relevant', 'to', 'users', 'provide', 'personalized', 'recommendations', 'of', 'events', 'to', 'users', 'etc', 'to', 'increase', 'our', 'client', 's', 'productivity', 'we', 'are', 'looking', 'for', 'research', 'scientists', 'with', 'experience', 'running', 'a', 'machine', 'learning', 'project', 'from', 'inception', 'to', 'completion', 'and', 'specifically', 'with', 'a', 'background', 'and', 'interest', 'in', 'one', 'or', 'more', 'of', 'the', 'following', 'areas', 'state', 'of', 'the', 'art', 'deep', 'learning', 'e', 'g', 'hyper', 'parameter', 'tuning', 'sequence', 'to', 'sequence', 'methods', 'word', 'entity', 'embeddings', 'cnns', 'etc', 'model', 'evaluation', 'feature', 'engineering', 'big', 'data', 'experience', 'familiarly', 'with', 'time', 'series', 'analytics', 'we', 'll', 'trust', 'you', 'to', 'drive', 'projects', 'as', 'the', 'principle', 'point', 'of', 'contact', 'with', 'the', 'ability', 'to', 'determine', 'and', 'elaborate', 'on', 'suitable', 'metrics', 'as', 'well', 'as', 'methods', 'write', 'test', 'and', 'maintain', 'production', 'quality', 'code', 'mainly', 'c', 'publish', 'papers', 'and', 'attend', 'conferences', 'in', 'leading', 'venues', 'representing', 'our', 'research', 'you', 'll', 'need', 'to', 'have', 'strong', 'computer', 'science', 'fundamentals', 'algorithms', 'data', 'structures', 'a', 'track', 'record', 'of', 'relevant', 'research', 'solid', 'background', 'in', 'machine', 'learning', 'and', 'or', 'statistics', 'publication', 'history', 'experience', 'with', 'a', 'deep', 'learning', 'framework', 'e', 'g', 'tensorflow', 'pytorch', 'keras', 'cntk', 'etc', 'is', 'helpful', 'experience', 'with', 'nlp', 'is', 'also', 'very', 'useful']\n",
            "---\n",
            "['venmo', 'about', 'us', 'venmo', 'was', 'founded', 'on', 'the', 'principles', 'of', 'breaking', 'down', 'the', 'intimidating', 'barriers', 'around', 'financial', 'transactions', 'to', 'make', 'them', 'intuitive', 'friendly', 'and', 'even', 'fun', 'and', 'it', 'worked', 'people', 'love', 'sending', 'money', 'with', 'venmo', 'and', 'we’re', 'growing', 'by', 'leaps', 'and', 'bounds', 'but', 'we’re', 'only', 'just', 'getting', 'started', 'we', 'want', 'to', 'take', 'that', 'magic', 'of', 'sending', 'money', 'with', 'venmo', 'and', 'cascade', 'it', 'into', 'every', 'place', 'where', 'people', 'use', 'money', 'that', 'means', 'connecting', 'people', 'to', 'their', 'money', 'in', 'the', 'most', 'intuitive', 'and', 'fun', 'way', 'possible', 'then', 'connecting', 'people', 'with', 'each', 'other', 'users', 'already', 'love', 'venmo', 'but', 'we', 'know', 'there', 'are', 'lots', 'of', 'things', 'we', 'haven’t', 'thought', 'of', 'to', 'make', 'the', 'experience', 'of', 'using', 'venmo', 'even', 'more', 'delightful', 'and', 'valuable', 'all', 'that’s', 'going', 'to', 'take', 'a', 'lot', 'of', 'figuring', 'out', 'let’s', 'figure', 'it', 'out', 'together', 'data', 'analytics', 'at', 'venmo', 'analytics', 'plays', 'a', 'crucial', 'role', 'across', 'venmo', 'we', 'approach', 'problems', 'inquisitively', 'and', 'with', 'a', 'desire', 'to', 'find', 'solutions', 'in', 'our', 'data', 'we', 'believe', 'that', 'analytics', 'should', 'drive', 'business', 'decisions', 'across', 'the', 'company', 'in', 'order', 'to', 'keep', 'our', 'product', 'simple', 'joyful', 'and', 'delightful', 'data', 'scientist', 'at', 'venmo', 'venmo', 'is', 'looking', 'for', 'a', 'curious', 'proactive', 'and', 'organized', 'analyst', 'to', 'work', 'collaboratively', 'with', 'the', 'various', 'teams', 'across', 'the', 'organization', 'you', 'should', 'be', '“full', 'stack”', 'equally', 'capable', 'of', 'orchestrating', 'data', 'pipelines', 'using', 'infrastructure', 'built', 'by', 'data', 'engineers', 'digging', 'through', 'data', 'to', 'uncover', 'novel', 'insights', 'and', 'convincing', 'others', 'by', 'presenting', 'those', 'insights', 'in', 'a', 'clear', 'and', 'concise', 'way', 'as', 'a', 'member', 'of', 'the', 'analytics', 'team', 'you’ll', 'drive', 'critical', 'business', 'decisions', 'build', 'out', 'our', 'analytical', 'capabilities', 'and', 'work', 'on', 'perplexing', 'problems', 'you’ll', 'become', 'a', 'thought', 'leader', 'and', 'an', 'integral', 'part', 'of', 'a', 'company', 'that', 'makes', 'payments', 'fun', 'what', 'you', 'll', 'do', 'design', 'and', 'analyze', 'experiments', 'to', 'support', 'product', 'development', 'define', 'and', 'evaluate', 'key', 'metrics', 'and', 'understand', 'what', 'moves', 'them', 'and', 'why', 'model', 'the', 'lifetime', 'value', 'of', 'our', 'users', 'write', 'etl', 'to', 'aggregate', 'data', 'out', 'of', 'disparate', 'sources', 'what', 'we’re', 'looking', 'for', '4', 'years', 'experience', 'in', 'an', 'analytical', 'or', 'technical', 'role', 'sql', 'guru', 'and', 'experience', 'in', 'an', 'analytical', 'programming', 'language', 'python', 'or', 'r', '2', 'years', 'experience', 'with', 'self', 'service', 'bi', 'tools', 'e', 'g', 'tableau', 'looker', 'strong', 'analytical', 'intuition', 'and', 'business', 'acumen', 'ability', 'to', 'define', 'relevant', 'metrics', 'and', 'communicate', 'them', 'clearly', 'to', 'cross', 'functional', 'partners', 'of', 'varying', 'technical', 'levels', 'to', 'influence', 'appropriate', 'and', 'accurate', 'decisions', 'we', 'know', 'the', 'confidence', 'gap', 'and', 'imposter', 'syndrome', 'can', 'get', 'in', 'the', 'way', 'of', 'meeting', 'spectacular', 'candidates', 'please', 'don', 't', 'hesitate', 'to', 'appl']\n",
            "---\n",
            "['sofi', 'who', 'we', 'are', 'sofi', 'is', 'a', 'digital', 'personal', 'finance', 'company', 'whose', 'mission', 'is', 'to', 'help', 'its', 'members', 'achieve', 'financial', 'independence', 'to', 'realize', 'their', 'ambitions', 'whether', 'that', 'be', 'to', 'buy', 'a', 'house', 'one', 'day', 'start', 'a', 'family', 'on', 'their', 'own', 'terms', 'or', 'be', 'debt', 'free', 'we', 'aim', 'to', 'be', 'at', 'the', 'center', 'of', 'our', 'members’', 'financial', 'lives', 'and', 'to', 'help', 'every', 'member', 'get', 'their', 'money', 'right®', 'by', 'joining', 'sofi', 'you’ll', 'become', 'part', 'of', 'a', 'forward', 'thinking', 'company', 'that', 'is', 'transforming', 'financial', 'services', 'by', 'embracing', 'technology', 'to', 'build', 'innovative', 'loan', 'products', 'investment', 'tools', 'and', 'more', 'one', 'of', 'the', 'fastest', 'growing', 'fintech', 'companies', 'we’ve', 'grown', 'from', '250', 'employees', 'in', '2015', 'to', 'over', '1', '500', 'employees', 'today', 'and', 'are', 'well', 'on', 'our', 'way', 'to', 'reaching', '1', 'million', 'members', 'with', 'offices', 'across', 'the', 'us', 'we', 'offer', 'the', 'excitement', 'of', 'a', 'rapidly', 'growing', 'startup', 'with', 'the', 'stability', 'of', 'a', 'seasoned', 'management', 'team', 'and', 'some', 'of', 'the', 'best', 'talent', 'around', 'as', 'an', 'employer', 'we', 'strive', 'to', 'hire', 'employees', 'who', 'are', 'committed', 'to', 'both', 'our', 'company’s', 'mission', 'and', 'our', 'desire', 'to', 'build', 'the', 'best', 'culture', 'in', 'the', 'world', 'if', 'you', 'are', 'driven', 'passionate', 'about', 'what', 'you', 'do', 'and', 'excited', 'about', 'the', 'sofi', 'mission', 'we', 'would', 'love', 'to', 'hear', 'from', 'you', 'the', 'role', 'sofi', 'is', 'looking', 'for', 'a', 'senior', 'staff', 'data', 'scientist', 'analyst', 'to', 'deliver', 'data', 'driven', 'insights', 'to', 'support', 'our', 'invest', 'team', 's', 'decisions', 'and', 'strategies', 'for', 'invest', 'team', 'in', 'this', 'role', 'you', 'will', 'be', 'responsible', 'for', 'optimizing', 'invest', 'product', 'performance', 'through', 'experimentation', 'design', 'business', 'analytics', 'and', 'predictive', 'analytics', 'success', 'in', 'this', 'role', 'hinges', 'on', 'your', 'technical', 'aptitude', 'quantitative', 'abilities', 'and', 'business', 'acumen', 'you', 'know', 'how', 'to', 'plow', 'through', 'data', 'with', 'sql', 'python', 'r', 'tableau', 'surface', 'insights', 'using', 'math', 'statistics', 'ml', 'techniques', 'and', 'measure', 'the', 'business', 'impact', 'using', 'efficiency', 'conversion', 'profit', 'metrics', 'what', 'you', 'll', 'do', 'work', 'with', 'business', 'unit', 'leaders', 'and', 'product', 'teams', 'to', 'identify', 'business', 'opportunities', 'measure', 'kpis', 'to', 'craft', 'compelling', 'stories', 'make', 'data', 'driven', 'recommendations', 'and', 'drive', 'informed', 'actions', 'own', 'end', 'to', 'end', 'product', 'analytics', 'workflow', 'including', 'formulating', 'success', 'metrics', 'socializing', 'them', 'across', 'the', 'organization', 'and', 'creating', 'dashboards', 'reports', 'design', 'analyze', 'and', 'interpret', 'the', 'results', 'of', 'experiments', 'that', 'could', 'optimize', 'product', 'performance', 'work', 'cross', 'functional', 'with', 'engineering', 'product', 'teams', 'and', 'data', 'architects', 'to', 'ensure', 'data', 'is', 'being', 'captured', 'and', 'reports', 'are', 'accurate', 'what', 'you', 'll', 'need', '5', 'years', 'of', 'relevant', 'work', 'experience', 'business', 'analytics', 'kpi', 'dashboard', 'development', 'business', 'performance', 'analysis', '3', 'year', 'experience', 'with', 'investment', 'platforms', 'in', 'fintech', 'or', 'banking', 'environment', 'strong', 'data', 'visualization', 'and', 'presentation', 'skills', 'proficient', 'with', 'sql', 'r', 'python', 'tableau', 'excel', 'and', 'powerpoint', 'strong', 'analytical', 'problem', 'solving', 'and', 'critical', 'thinking', 'skills', 'strong', 'stakeholder', 'management', 'skills', 'intellectual', 'curiosity', 'and', 'aptitude', 'to', 'pick', 'up', 'new', 'technical', 'skills', 'ability', 'to', 'initiate', 'and', 'drive', 'projects', 'to', 'completion', 'with', 'minimal', 'guidance', 'bs', 'or', 'ideally', 'ms', 'mba', 'degree', 'in', 'computer', 'science', 'finance', 'economics', 'math', 'physics', 'engineering', 'or', 'other', 'quantitative', 'fields', 'why', 'you', 'll', 'love', 'working', 'here', 'company', 'paid', 'lunch', 'program', 'a', 'fully', 'stocked', 'kitchen', 'and', 'subsidized', 'gym', 'membership', 'competitive', 'salary', 'packages', 'and', 'bonuses', 'a', 'flexible', 'vacation', 'policy', 'allows', 'you', 'to', 'truly', 'relax', 'and', 'reboot', 'comprehensive', 'health', 'vision', 'dental', 'and', 'life', 'insurance', 'as', 'well', 'as', 'disability', 'benefits', '90', '100', 'of', 'health', 'vision', 'and', 'dental', 'premiums', 'paid', 'by', 'sofi', 'for', 'employees', 'and', 'their', 'dependents', '401', 'k', 'and', 'education', 'on', 'retirement', 'planning', 'tuition', 'reimbursement', 'on', 'approved', 'programs', 'up', 'to', '5', '250', 'a', 'year', 'monthly', 'contribution', 'to', 'help', 'you', 'pay', 'off', 'your', 'student', 'loans', 'pursuant', 'to', 'the', 'san', 'francisco', 'fair', 'chance', 'ordinance', 'we', 'will', 'consider', 'for', 'employment', 'qualified', 'applicants', 'with', 'arrest', 'and', 'conviction', 'records']\n",
            "---\n",
            "['goldman', 'sachs', 'collaborate', 'with', 'technology', 'division', 'teams', 'as', 'a', 'pool', 'of', 'developers', 'dedicated', 'to', 'delivering', 'key', 'priorities', 'act', 'as', '‘surge', 'squad’', 'responsible', 'for', 'accelerating', 'a', 'specific', 'high', 'impact', 'technology', 'division', 'project', 'you', 'will', 'be', 'expected', 'to', 'conduct', 'world', 'class', 'research', 'in', 'areas', 'of', 'your', 'specialization', 'within', 'the', 'domain', 'of', 'artificial', 'intelligence', '–', 'natural', 'language', 'understanding', 'causal', 'extraction', 'knowledge', 'representation', 'and', 'reasoning', 'you', 'will', 'work', 'with', 'other', 'researchers', 'and', 'developers', 'within', 'the', 'r', 'd', 'group', 'and', 'with', 'other', 'teams', 'in', 'gs', 'to', 'develop', 'breakthrough', 'ideas', 'in', 'this', 'space', 'create', 'proof', 'of', 'concept', 'realizations', 'develop', 'intellectual', 'property', 'and', 'participate', 'in', 'external', 'research', 'communities', 'giving', 'talks', 'publishing', 'papers', 'attending', 'conferences', 'organizing', 'meetings', 'how', 'you', 'will', 'fulfill', 'your', 'potential', 'responsibilities', 'and', 'qualifications', 'conduct', 'research', 'in', 'the', 'areas', 'of', 'artificial', 'intelligence', 'manage', 'individual', 'project', 'priorities', 'deadlines', 'and', 'deliverable', 'skills', 'and', 'experience', 'we', 'are', 'looking', 'for', 'phd', 'preferred', 'qualifications', 'research', 'experience', 'about', 'goldman', 'sachs', 'the', 'goldman', 'sachs', 'group', 'inc', 'is', 'a', 'leading', 'global', 'investment', 'banking', 'securities', 'and', 'investment', 'management', 'firm', 'that', 'provides', 'a', 'wide', 'range', 'of', 'financial', 'services', 'to', 'a', 'substantial', 'and', 'diversified', 'client', 'base', 'that', 'includes', 'corporations', 'financial', 'institutions', 'governments', 'and', 'individuals', 'founded', 'in', '1869', 'the', 'firm', 'is', 'headquartered', 'in', 'new', 'york', 'and', 'maintains', 'offices', 'in', 'all', 'major', 'financial', 'centers', 'around', 'the', 'world', 'â©', 'the', 'goldman', 'sachs', 'group', 'inc', '2019', 'all', 'rights', 'reserved', 'goldman', 'sachs', 'is', 'an', 'equal', 'employment', 'affirmative', 'action', 'employer', 'female', 'minority', 'disability', 'vet', 'division', 'engineering']\n",
            "---\n",
            "['dow', 'jones', 'we', 'are', 'looking', 'for', 'a', 'data', 'scientist', 'to', 'join', 'the', 'data', 'science', 'analytics', 'team', 'for', 'the', 'wall', 'street', 'journal’s', 'membership', 'group', 'in', 'this', 'role', 'you', 'will', 'lead', 'our', 'efforts', 'in', 'machine', 'learning', 'and', 'product', 'analytics', 'working', 'on', 'the', 'development', 'and', 'refinement', 'of', 'critical', 'models', 'for', 'our', 'business—including', 'the', 'propensity', 'model', 'behind', 'wsj’s', 'dynamic', 'paywall', 'additionally', 'you', 'will', 'serve', 'as', 'an', 'evangelist', 'for', 'analytics', 'within', 'our', 'organization', 'and', 'develop', 'metrics', 'for', 'measuring', 'engagement', 'within', 'our', 'products', 'the', 'role', 'will', 'require', 'a', 'strong', 'understanding', 'of', 'data', 'wrangling', 'log', 'level', 'usage', 'data', 'and', 'production', 'models', 'you', 'will', 'need', 'strong', 'organization', 'skills', 'and', 'will', 'oversee', 'the', 'execution', 'of', 'large', 'scale', 'data', 'projects', 'an', 'interest', 'in', 'best', 'in', 'class', 'design', 'and', 'engineering', 'as', 'well', 'as', 'visualization', 'and', 'storytelling', 'will', 'also', 'be', 'critical', 'to', 'your', 'success', 'in', 'this', 'role', 'requirements', 'you', 'have', 'at', 'minimum', 'bachelor’s', 'degree', 'in', 'information', 'systems', 'computer', 'science', 'mathematics', 'data', 'analytics', 'data', 'science', 'or', 'a', 'related', 'quantitative', 'discipline', 'applicants', 'with', 'strong', 'technical', 'experience', 'and', 'a', 'professional', 'background', 'in', 'media', 'are', 'also', 'encouraged', 'to', 'apply', 'at', 'least', '2', '5', 'years', 'of', 'experience', 'working', 'in', 'a', 'data', 'related', 'role', 'is', 'preferred', 'you', 'have', 'strong', 'coding', 'skills', 'in', 'r', 'and', 'or', 'python', 'and', 'understand', 'version', 'control', 'software', 'git', 'github', 'you', 'have', 'a', 'mastery', 'of', 'analytics', 'tools', 'sql', 'tableau', 'adobe', 'google', 'analytics', 'you', 'are', 'well', 'versed', 'in', 'the', 'fundamentals', 'of', 'statistics', 'and', 'have', 'a', 'working', 'understanding', 'of', 'machine', 'learning', 'algorithms', 'and', 'their', 'applications', 'you', 'have', 'an', 'entrepreneurial', 'attitude', 'toward', 'work', 'and', 'sweat', 'the', 'details', 'you', 'have', 'an', 'interest', 'in', 'continued', 'learning', 'and', 'stay', 'well', 'versed', 'in', 'new', 'technologies', 'that', 'can', 'be', 'applied', 'to', 'your', 'work']\n",
            "---\n",
            "['point72', 'at', 'point72', 'mi', 'data', 'our', 'data', 'scientists', 'sift', 'through', 'petabytes', 'of', 'unstructured', 'data', 'from', 'diverse', 'sources', 'to', 'discover', 'trends', 'and', 'insights', 'that', 'help', 'point72’s', 'portfolio', 'managers', 'create', 'new', 'investment', 'theses', 'we', 'combine', 'an', 'experiment', 'based', 'approach', 'with', 'the', 'strongest', 'possible', 'management', 'support', 'and', 'the', 'freedom', 'to', 'innovate', 'unencumbered', 'by', 'bureaucracy', 'we', 'encourage', 'our', 'data', 'scientists', 'to', 'imagine', 'the', 'impossible', 'and', 'provide', 'the', 'structure', 'to', 'bring', 'those', 'ideas', 'to', 'market', 'in', 'months', 'not', 'years', 'what', 'you’ll', 'do', 'in', 'this', 'role', 'you', 'will', 'our', 'data', 'scientists', 'conduct', 'research', 'through', 'data', 'mining', 'and', 'statistical', 'modeling', 'to', 'discover', 'insights', 'from', 'big', 'data', 'that', 'are', 'used', 'by', 'our', 'investment', 'professionals', 'to', 'make', 'investment', 'decisions', 'you', 'will', 'have', 'the', 'opportunity', 'to', 'work', 'in', 'a', 'highly', 'collegial', 'environment', 'that', 'emphasizes', 'teaching', 'and', 'learning', 'as', 'a', 'team', 'tackle', 'the', 'challenges', 'of', 'featurizing', 'and', 'modeling', 'large', 'and', 'unstructured', 'data', 'using', 'machine', 'learning', 'and', 'statistical', 'techniques', 'manage', 'all', 'aspects', 'of', 'the', 'research', 'and', 'execution', 'process', 'including', 'methodology', 'selection', 'data', 'collection', 'and', 'quality', 'modeling', 'and', 'analysis', 'and', 'performance', 'monitoring', 'deliver', 'research', 'findings', 'to', 'investment', 'teams', 'portfolio', 'managers', 'and', 'other', 'internal', 'clients', 'work', 'within', 'a', 'team', 'to', 'help', 'drive', 'technical', 'innovation', 'through', 'a', 'collaborative', 'r', 'd', 'process', 'what’s', 'required', 'we', 'look', 'for', 'candidates', 'with', 'extensive', 'knowledge', 'in', 'machine', 'learning', 'statistical', 'models', 'and', 'data', 'mining', 'tools', 'and', 'a', 'proven', 'track', 'record', 'of', 'working', 'with', 'large', 'structured', 'and', 'unstructured', 'data', 'sets', 'to', 'extract', 'timely', 'actionable', 'insights', 'other', 'requirements', 'include', 'ms', 'or', 'phd', 'degree', 'in', 'a', 'quantitative', 'discipline', '3', 'years', 'of', 'industry', 'working', 'experience', 'in', 'a', 'role', 'that', 'requires', 'advanced', 'statistical', 'analysis', '3', 'years', 'of', 'hands', 'on', 'working', 'experience', 'with', 'varied', 'and', 'complex', 'data', 'sets', 'strong', 'programming', 'skills', 'in', 'the', 'following', 'languages', 'sql', 'python', 'preferred', 'r', 'scala', 'spark', 'ability', 'to', 'think', 'creatively', 'and', 'see', 'the', 'big', 'picture', 'as', 'well', 'as', 'finer', 'details']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7r4lOCBrljZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d741c0e2-0708-49bd-a635-7fedecd0267a"
      },
      "source": [
        "stop_words"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['’ll',\n",
              " 'ca',\n",
              " 'out',\n",
              " 'into',\n",
              " 'seems',\n",
              " 'doing',\n",
              " 'it',\n",
              " 'beforehand',\n",
              " 'down',\n",
              " 'from',\n",
              " 'three',\n",
              " 'neither',\n",
              " \"'m\",\n",
              " 'made',\n",
              " 'former',\n",
              " 'elsewhere',\n",
              " 'if',\n",
              " 'take',\n",
              " '’ve',\n",
              " 'put',\n",
              " 'seemed',\n",
              " 'forty',\n",
              " 'eight',\n",
              " 'whereafter',\n",
              " 'perhaps',\n",
              " 'at',\n",
              " '‘s',\n",
              " 'say',\n",
              " 'each',\n",
              " 'always',\n",
              " 'as',\n",
              " 'was',\n",
              " '’re',\n",
              " 'about',\n",
              " 'him',\n",
              " 'back',\n",
              " 'just',\n",
              " 'really',\n",
              " 'myself',\n",
              " 'sometime',\n",
              " 'twelve',\n",
              " 'wherein',\n",
              " 'well',\n",
              " 'with',\n",
              " 'once',\n",
              " 'there',\n",
              " 'seeming',\n",
              " '‘re',\n",
              " 'hereafter',\n",
              " 'bottom',\n",
              " 'third',\n",
              " 'nor',\n",
              " 'might',\n",
              " 'why',\n",
              " 'five',\n",
              " \"'ll\",\n",
              " 'call',\n",
              " 'give',\n",
              " 'in',\n",
              " 'have',\n",
              " 'do',\n",
              " 'where',\n",
              " \"n't\",\n",
              " 'please',\n",
              " 'their',\n",
              " 'among',\n",
              " 'some',\n",
              " 'yourself',\n",
              " 'should',\n",
              " 'almost',\n",
              " 'below',\n",
              " 'over',\n",
              " 'whereupon',\n",
              " 'therefore',\n",
              " 'were',\n",
              " 'would',\n",
              " 'you',\n",
              " 'else',\n",
              " 'every',\n",
              " 'become',\n",
              " 'serious',\n",
              " 'alone',\n",
              " 'twenty',\n",
              " 'them',\n",
              " 'thereafter',\n",
              " 'often',\n",
              " 'whither',\n",
              " \"'s\",\n",
              " 'but',\n",
              " 'hundred',\n",
              " 'an',\n",
              " \"'d\",\n",
              " 'one',\n",
              " 'side',\n",
              " 'herself',\n",
              " 'being',\n",
              " 'on',\n",
              " 'when',\n",
              " 'she',\n",
              " 'around',\n",
              " '‘ve',\n",
              " 'much',\n",
              " 'whatever',\n",
              " 'since',\n",
              " 'whenever',\n",
              " 'because',\n",
              " 'although',\n",
              " 'same',\n",
              " 'thereby',\n",
              " 'nobody',\n",
              " 'done',\n",
              " 'mine',\n",
              " 'so',\n",
              " 'those',\n",
              " 'anywhere',\n",
              " 'next',\n",
              " 'everything',\n",
              " 'seem',\n",
              " 'and',\n",
              " 'cannot',\n",
              " 'still',\n",
              " 'enough',\n",
              " 'meanwhile',\n",
              " 'they',\n",
              " 'which',\n",
              " 'after',\n",
              " 'few',\n",
              " 'my',\n",
              " 'somewhere',\n",
              " 'though',\n",
              " 'your',\n",
              " 'nothing',\n",
              " 'six',\n",
              " 'whereby',\n",
              " 'most',\n",
              " 'go',\n",
              " '’s',\n",
              " 'see',\n",
              " 'anyway',\n",
              " 'no',\n",
              " 'otherwise',\n",
              " 'moreover',\n",
              " 'becoming',\n",
              " 'amongst',\n",
              " 'something',\n",
              " 'thence',\n",
              " 'therein',\n",
              " '‘d',\n",
              " 'last',\n",
              " 'herein',\n",
              " 'i',\n",
              " 'more',\n",
              " 'of',\n",
              " 'very',\n",
              " 'until',\n",
              " 'whether',\n",
              " 'all',\n",
              " 'thru',\n",
              " 'by',\n",
              " 'noone',\n",
              " 'amount',\n",
              " 'the',\n",
              " 'not',\n",
              " 'unless',\n",
              " 'make',\n",
              " 'beside',\n",
              " 'did',\n",
              " 'ten',\n",
              " 'up',\n",
              " 'are',\n",
              " 'fifty',\n",
              " 'her',\n",
              " 'however',\n",
              " 'within',\n",
              " 'how',\n",
              " 'another',\n",
              " 'several',\n",
              " 'someone',\n",
              " 'many',\n",
              " 'name',\n",
              " 'also',\n",
              " 'get',\n",
              " 'hereby',\n",
              " 'or',\n",
              " 'ourselves',\n",
              " 'everywhere',\n",
              " 'any',\n",
              " 'both',\n",
              " 'latter',\n",
              " 'becomes',\n",
              " 'may',\n",
              " 'now',\n",
              " 'other',\n",
              " 'wherever',\n",
              " 'who',\n",
              " \"'ve\",\n",
              " 'is',\n",
              " 'such',\n",
              " 'then',\n",
              " 'together',\n",
              " 'whence',\n",
              " 'own',\n",
              " 'front',\n",
              " '’m',\n",
              " 'along',\n",
              " '’d',\n",
              " 'except',\n",
              " 'for',\n",
              " 'four',\n",
              " 're',\n",
              " 'somehow',\n",
              " 'behind',\n",
              " 'namely',\n",
              " 'hereupon',\n",
              " 'these',\n",
              " 'various',\n",
              " 'yours',\n",
              " 'must',\n",
              " 'already',\n",
              " 'none',\n",
              " 'whose',\n",
              " 'will',\n",
              " 'per',\n",
              " 'again',\n",
              " 'toward',\n",
              " 'ever',\n",
              " 'am',\n",
              " 'n’t',\n",
              " 'empty',\n",
              " 'here',\n",
              " 'rather',\n",
              " 'be',\n",
              " 'top',\n",
              " 'thus',\n",
              " 'without',\n",
              " 'during',\n",
              " 'nine',\n",
              " 'less',\n",
              " 'further',\n",
              " 'a',\n",
              " 'through',\n",
              " 'too',\n",
              " 'two',\n",
              " 'themselves',\n",
              " 'us',\n",
              " 'sometimes',\n",
              " 'we',\n",
              " 'whole',\n",
              " 'besides',\n",
              " 'thereupon',\n",
              " 'using',\n",
              " 'upon',\n",
              " 'formerly',\n",
              " 'itself',\n",
              " 'either',\n",
              " 'others',\n",
              " 'nowhere',\n",
              " 'can',\n",
              " 'due',\n",
              " 'quite',\n",
              " 'to',\n",
              " 'onto',\n",
              " 'part',\n",
              " 'this',\n",
              " 'towards',\n",
              " 'has',\n",
              " 'beyond',\n",
              " 'latterly',\n",
              " 'had',\n",
              " 'between',\n",
              " 'afterwards',\n",
              " 'than',\n",
              " 'his',\n",
              " 'our',\n",
              " 'while',\n",
              " 'sixty',\n",
              " 'that',\n",
              " 'before',\n",
              " 'does',\n",
              " '‘m',\n",
              " 'me',\n",
              " 'used',\n",
              " 'regarding',\n",
              " 'via',\n",
              " 'n‘t',\n",
              " 'never',\n",
              " 'anyhow',\n",
              " 'hers',\n",
              " 'could',\n",
              " 'himself',\n",
              " 'keep',\n",
              " 'eleven',\n",
              " 'first',\n",
              " 'been',\n",
              " 'became',\n",
              " 'he',\n",
              " 'anyone',\n",
              " 'hence',\n",
              " '‘ll',\n",
              " 'nevertheless',\n",
              " 'under',\n",
              " 'whoever',\n",
              " 'ours',\n",
              " 'least',\n",
              " \"'re\",\n",
              " 'only',\n",
              " 'anything',\n",
              " 'its',\n",
              " 'mostly',\n",
              " 'indeed',\n",
              " 'whom',\n",
              " 'what',\n",
              " 'full',\n",
              " 'against',\n",
              " 'yourselves',\n",
              " 'show',\n",
              " 'off',\n",
              " 'whereas',\n",
              " 'throughout',\n",
              " 'fifteen',\n",
              " 'across',\n",
              " 'even',\n",
              " 'everyone',\n",
              " 'move',\n",
              " 'above',\n",
              " 'yet',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " 'two']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uRVMK7e3AJd",
        "colab_type": "code",
        "outputId": "b79244c5-4bfc-444f-c96c-c251b49a5469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# word split\n",
        "for names in df_jd.columns:\n",
        "  for i in range(len(df_jd[names])):\n",
        "\n",
        "    df_clean[names][i] = df_jd[names][i].split(' ')\n",
        "    #df_clean[names][i] = pd.DataFrame(re.split(' |, |\\n',df_jd[names][i]))\n",
        "#[x.strip() for x in my_string.split(',')]\n",
        "\n",
        "df_clean.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Financial</th>\n",
              "      <th>Healthcare</th>\n",
              "      <th>e-com</th>\n",
              "      <th>social media</th>\n",
              "      <th>consumer</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Two, Sigma,, The, Alpha, Insights, team, at, ...</td>\n",
              "      <td>[Novo, Nordisk,, The, Clinical,, Medical, and,...</td>\n",
              "      <td>[Walmart, Position, Description\\n\\nA, Staff, D...</td>\n",
              "      <td>[Facebook,, We’re, looking, for, Data, Scienti...</td>\n",
              "      <td>[Uniliever,, Background, &amp;, Purpose, of, the, ...</td>\n",
              "      <td>[Google,, Note:, By, applying, to, this, posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Prudential, Financial,\\n\\nAs, we, create, a, ...</td>\n",
              "      <td>[Aetna,, Description:\\r\\nIt’s, a, new, day, in...</td>\n",
              "      <td>[Walmart,, As, a, part, of, Walmart’s, Custome...</td>\n",
              "      <td>[Facebook,, With, over, 2.1, billion, people,,...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Machine, Learning, Research, Scientist, -, Pa...</td>\n",
              "      <td>[Blink, Health,, Blink, Health, (, https://www...</td>\n",
              "      <td>[Amazon,, Description\\r\\n\\r\\nAre, you, seeking...</td>\n",
              "      <td>[New, York, Times,, The, New, York, Times, is,...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Venmo,, About, Us\\n\\nVenmo, was, founded, on,...</td>\n",
              "      <td>[Oscar,, Hi,, we're, Oscar., We're, hiring, a,...</td>\n",
              "      <td>[Amazon,, Description\\r\\n\\r\\nAmazon, is, looki...</td>\n",
              "      <td>[Wolters, Kluwer,, Data, Scientist, –, R000601...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Sofi,, Who, We, Are\\n\\nSoFi, is, a, digital, ...</td>\n",
              "      <td>[Oscar,, Hi,, we're, Oscar., We're, hiring, a,...</td>\n",
              "      <td>[Amazon,, Where, will, Amazon's, growth, come,...</td>\n",
              "      <td>[Bloomberg,, News, and, social, media, move, f...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                          Financial  ...                                        Information\n",
              "0  [Two, Sigma,, The, Alpha, Insights, team, at, ...  ...  [Google,, Note:, By, applying, to, this, posit...\n",
              "1  [Prudential, Financial,\\n\\nAs, we, create, a, ...  ...                                                 []\n",
              "2  [Machine, Learning, Research, Scientist, -, Pa...  ...                                                 []\n",
              "3  [Venmo,, About, Us\\n\\nVenmo, was, founded, on,...  ...                                                 []\n",
              "4  [Sofi,, Who, We, Are\\n\\nSoFi, is, a, digital, ...  ...                                                 []\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdD68VKNfjD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ace99997-809e-4382-ae47-0212398bdaa3"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Financial</th>\n",
              "      <th>Healthcare</th>\n",
              "      <th>e-com</th>\n",
              "      <th>social media</th>\n",
              "      <th>consumer</th>\n",
              "      <th>Information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>two sigma  the alpha insights team at two sigm...</td>\n",
              "      <td>novo nordisk  the clinical  medical and regula...</td>\n",
              "      <td>walmart position description  a staff data sci...</td>\n",
              "      <td>facebook  we’re looking for data scientists to...</td>\n",
              "      <td>uniliever  background   purpose of the job  as...</td>\n",
              "      <td>google  note  by applying to this position you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prudential financial   as we create a diverse ...</td>\n",
              "      <td>aetna  description   it’s a new day in health ...</td>\n",
              "      <td>walmart  as a part of walmart’s customer data ...</td>\n",
              "      <td>facebook  with over 2 1 billion people  our co...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>machine learning research scientist   pattern ...</td>\n",
              "      <td>blink health  blink health   https   www blink...</td>\n",
              "      <td>amazon  description    are you seeking an envi...</td>\n",
              "      <td>new york times  the new york times is a techno...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>venmo  about us  venmo was founded on the prin...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  description    amazon is looking for a...</td>\n",
              "      <td>wolters kluwer  data scientist – r0006015  wol...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sofi  who we are  sofi is a digital personal f...</td>\n",
              "      <td>oscar  hi  we re oscar  we re hiring a data sc...</td>\n",
              "      <td>amazon  where will amazon s growth come from i...</td>\n",
              "      <td>bloomberg  news and social media move financia...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                          Financial  ...                                        Information\n",
              "0  two sigma  the alpha insights team at two sigm...  ...  google  note  by applying to this position you...\n",
              "1  prudential financial   as we create a diverse ...  ...                                                   \n",
              "2  machine learning research scientist   pattern ...  ...                                                   \n",
              "3  venmo  about us  venmo was founded on the prin...  ...                                                   \n",
              "4  sofi  who we are  sofi is a digital personal f...  ...                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPFyucIIsvPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_clean(df, columns):\n",
        "  '''\n",
        "  input: dataset and column name\n",
        "  output: lowercase word without stop words\n",
        "  '''\n",
        "  df_clean = []\n",
        "  for discription in df[columns]:\n",
        "    #lower_words = []\n",
        "    for word in discription:\n",
        "      if not word.lower() in stopwords:\n",
        "        #lower_words.append(word.lower())\n",
        "        df_clean.append(word.lower())\n",
        "    #df_clean.append(lower_words)\n",
        "  return df_clean\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9twn8tayXVR",
        "colab_type": "code",
        "outputId": "467e3fe6-d1c4-462a-82e3-f4ee334eac69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "text_financial = word_clean(df_clean, 'Financial')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-5dca86387d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_financial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Financial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-134-ff549293c5eb>\u001b[0m in \u001b[0;36mword_clean\u001b[0;34m(df, columns)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#lower_words = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiscription\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m#lower_words.append(word.lower())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdf_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGdv6G-IfrMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_clean(df1, 'Financial');\n",
        "# check stop words\n",
        "w = ['(1)', '(2)','(3)','&', 'r,)','(e.g.','e.g.','etc.).','ms','3-5','3','r,','3+','â©','2+']\n",
        "stopwords1 = list(stopwords)+(w)\n",
        "#for i in w:\n",
        "#  nlp.vocab[i].is_stop = True\n",
        "#nlp.vocab['christchurch'].is_stop = True\n",
        "#nlp.vocab['new zealand'].is_stop = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64cRUxDBQ_wI",
        "colab_type": "text"
      },
      "source": [
        "#### keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a71w1Q5lRJ8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=pd.Series(text_financial)#.values.replace('\\\\n','')\n",
        "test.replace('\\\\n', '', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OdiigoAUGRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cac99812-00bd-433f-94bf-a3ceded95737"
      },
      "source": [
        "df_kw.columns"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['statistics', 'machine learning', 'deep learning', 'python langugage',\n",
              "       'R language', 'nlp', 'data engineering', 'visualization',\n",
              "       'soft skills'],\n",
              "      dtype='object', name=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Tu6YYyTFay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_stats = [nlp(text) for text in df_kw['statistics'].dropna(axis=0)]\n",
        "words_ml = [nlp(text) for text in df_kw['machine learning'].dropna(axis=0)]\n",
        "words_dl = [nlp(text) for text in df_kw['deep learning'].dropna(axis=0)]\n",
        "words_py = [nlp(text) for text in df_kw['python langugage'].dropna(axis=0)]\n",
        "words_r = [nlp(text) for text in df_kw['R language'].dropna(axis=0)]\n",
        "words_nlp = [nlp(text) for text in df_kw['nlp'].dropna(axis=0)]\n",
        "words_de = [nlp(text) for text in df_kw['data engineering'].dropna(axis=0)]\n",
        "words_vis = [nlp(text) for text in df_kw['visualization'].dropna(axis=0)]\n",
        "words_ss = [nlp(text) for text in df_kw['soft skills'].dropna(axis=0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj5R8oo9RCbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function that does phrase matching and builds a candidate profile\n",
        "def create_profile(file):\n",
        "    text = pdfextract(file) \n",
        "    text = str(text)\n",
        "    text = text.replace(\"\\\\n\", \"\")\n",
        "    text = text.lower()\n",
        "    #below is the csv where we have all the keywords, you can customize your own\n",
        "    keyword_dict = pd.read_csv('D:/NLP_Resume/resume/template_new.csv')\n",
        "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
        "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
        "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
        "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
        "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
        "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
        "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
        "\n",
        "    matcher = PhraseMatcher(nlp.vocab)\n",
        "    matcher.add('Stats', None, *stats_words)\n",
        "    matcher.add('NLP', None, *NLP_words)\n",
        "    matcher.add('ML', None, *ML_words)\n",
        "    matcher.add('DL', None, *DL_words)\n",
        "    matcher.add('R', None, *R_words)\n",
        "    matcher.add('Python', None, *python_words)\n",
        "    matcher.add('DE', None, *Data_Engineering_words)\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    d = []  \n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
        "        span = doc[start : end]  # get the matched slice of the doc\n",
        "        d.append((rule_id, span.text))      \n",
        "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
        "    \n",
        "    ## convertimg string of keywords to dataframe\n",
        "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
        "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
        "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
        "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
        "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
        "    \n",
        "    base = os.path.basename(file)\n",
        "    filename = os.path.splitext(base)[0]\n",
        "       \n",
        "    name = filename.split('_')\n",
        "    name2 = name[0]\n",
        "    name2 = name2.lower()\n",
        "    ## converting str to dataframe\n",
        "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
        "    \n",
        "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
        "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
        "\n",
        "    return(dataf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4mqlPRuCZz1",
        "colab_type": "text"
      },
      "source": [
        "#### Topic Modeling with LSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qBEzleqf2as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj8fQIPDu6w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reindexed_data = np.array(word_clean(df_clean, 'Healthcare'))\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, smooth_idf=True)\n",
        "reindexed_data = reindexed_data#.values\n",
        "document_term_matrix = tfidf_vectorizer.fit_transform(reindexed_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldy7iEkA0T7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_topics = 6\n",
        "lsa_model = TruncatedSVD(n_components=n_topics)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(document_term_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfJGrhY75vAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_keys(topic_matrix):\n",
        "    '''\n",
        "    returns an integer list of predicted topic \n",
        "    categories for a given topic matrix\n",
        "    '''\n",
        "    keys = topic_matrix.argmax(axis=1).tolist()\n",
        "    return keys\n",
        "\n",
        "def keys_to_counts(keys):\n",
        "    '''\n",
        "    returns a tuple of topic categories and their \n",
        "    accompanying magnitudes for a given list of keys\n",
        "    '''\n",
        "    count_pairs = Counter(keys).items()\n",
        "    categories = [pair[0] for pair in count_pairs]\n",
        "    counts = [pair[1] for pair in count_pairs]\n",
        "    return (categories, counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daChq7CA5xjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lsa_keys = get_keys(lsa_topic_matrix)\n",
        "lsa_categories, lsa_counts = keys_to_counts(lsa_keys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdTZU2Aa50h3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_n_words(n, keys, document_term_matrix, tfidf_vectorizer):\n",
        "    '''\n",
        "    returns a list of n_topic strings, where each string contains the n most common \n",
        "    words in a predicted category, in order\n",
        "    '''\n",
        "    top_word_indices = []\n",
        "    for topic in range(n_topics):\n",
        "        temp_vector_sum = 0\n",
        "        for i in range(len(keys)):\n",
        "            if keys[i] == topic:\n",
        "                temp_vector_sum += document_term_matrix[i]\n",
        "        temp_vector_sum = temp_vector_sum.toarray()\n",
        "        top_n_word_indices = np.flip(np.argsort(temp_vector_sum)[0][-n:],0)\n",
        "        top_word_indices.append(top_n_word_indices)   \n",
        "    top_words = []\n",
        "    for topic in top_word_indices:\n",
        "        topic_words = []\n",
        "        for index in topic:\n",
        "            temp_word_vector = np.zeros((1,document_term_matrix.shape[1]))\n",
        "            temp_word_vector[:,index] = 1\n",
        "            the_word = tfidf_vectorizer.inverse_transform(temp_word_vector)[0][0]\n",
        "            topic_words.append(the_word.encode('ascii').decode('utf-8'))\n",
        "        top_words.append(\" \".join(topic_words))         \n",
        "    return top_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtqhRdzT53jS",
        "colab_type": "code",
        "outputId": "b602d846-8d88-4353-d7dc-20f0ddf73b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "top_n_words_lsa = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "\n",
        "for i in range(len(top_n_words_lsa)):\n",
        "    print(\"Topic {}: \".format(i+1), top_n_words_lsa[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1:  data driven addition\n",
            "Topic 2:  experience datasets text\n",
            "Topic 3:  analytics oscar analysis\n",
            "Topic 4:  health models care\n",
            "Topic 5:  work product business\n",
            "Topic 6:  new team projects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyNoC5l055wh",
        "colab_type": "code",
        "outputId": "c9d40f9f-627b-4aca-d495-c701820e5faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "top_3_words = get_top_n_words(3, lsa_keys, document_term_matrix, tfidf_vectorizer)\n",
        "labels = ['Topic {}: \\n'.format(i) + top_3_words[i] for i in lsa_categories]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,8))\n",
        "ax.bar(lsa_categories, lsa_counts);\n",
        "ax.set_xticks(lsa_categories);\n",
        "ax.set_xticklabels(labels);\n",
        "ax.set_ylabel('Number of review text');\n",
        "ax.set_title('LSA topic counts');\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHtCAYAAADLBSnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWcBZI-T59vT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hc = pd.DataFrame(word_clean(df_clean, 'Healthcare'), columns=['names'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw5Fp6QO7A02",
        "colab_type": "code",
        "outputId": "5c444b02-ef5d-47c2-91a1-f5cb53c1c7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "df_hc.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>novo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nordisk,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clinical,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>regulatory</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        names\n",
              "0        novo\n",
              "1    nordisk,\n",
              "2   clinical,\n",
              "3     medical\n",
              "4  regulatory"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pmVhtJH7W6W",
        "colab_type": "code",
        "outputId": "9663ea9b-1a2b-4395-972d-235c411c5e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "df_hc['names'].value_counts().nlargest(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data           66\n",
              "experience     35\n",
              "analytics      26\n",
              "work           26\n",
              "new            25\n",
              "health         25\n",
              "product        19\n",
              "team           18\n",
              "statistical    15\n",
              "business       15\n",
              "strong         11\n",
              "healthcare     11\n",
              "years          11\n",
              "develop        10\n",
              "care           10\n",
              "models         10\n",
              "development    10\n",
              "people         10\n",
              "analysis        9\n",
              "-               9\n",
              "Name: names, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8bTZhh97nuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}